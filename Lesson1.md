# 第 1 节：书生·浦语大模型全链路开源体系 作业

## 课程资料
第一次课程视频链接：https://www.bilibili.com/video/BV1Rc411b7ns/

第一次课程只需要记笔记，没有作业。第一次课程(1月9日)和第二次课程(1月12日)到本周末(1月13日)截止，笔记记录在 知乎/CSDN/Github 或者任何你习惯记录的地方，将你的笔记链接填写到 Github https://github.com/InternLM/tutorial/discussions/137 (https://github.com/jayjayhust/InternLM-Tutorial/blob/main/Lesson1.md)

## 课程笔记
- 数据：书生·万卷
  - 2TB
  - 覆盖多种模态与任务
  - OpenDataLab数据开放平台：https://opendatalab.org.cn/
- 大语言模型：InternLM
  - InternLM-7B：开源
  - InternLM-20B：开源
  - InternLM-123B：非开源
- 预训练：InternLM-Train
  - 并行训练，极致优化
  - 速度达到3600 tokens/sec/gpu
- 微调：XTuner
  - 支持全参数微调
  - 支持LoRA等低成本微调
- 部署：LM-Deploy
  - 全链路部署，性能领先
  - 每秒生成2000+ tokens
- 评测：OpenCompass
  - 全方位评测，性能可浮现
  - 80套评测集，40万道题目
- 应用（智能体）：Lagent, AgentLego
  - LLM的局限性
  - 智能体的能力
  - 轻量级智能体框架Lagent
  - 多模态智能体工具箱AgentLego